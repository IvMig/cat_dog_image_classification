{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat & dog image classification with Keras\n",
    "\n",
    "Выполнил: студент группы А-14м-16 Мигаль Иван.\n",
    "\n",
    "Описание:\n",
    "\n",
    "Решение задачи классификации образов (кошек и собак) с помощью keras. \n",
    "\n",
    "Для начала подключим необходимые модули и выведем их версии, в том числе версию python3. \n",
    "Также выведем абсолютный путь к папке с python3 (для разработчиков)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import matplotlib\n",
    "import urllib.request\n",
    "import http.client\n",
    "import json\n",
    "from itertools import compress\n",
    "import random\n",
    "from fabric.api import execute, local, run, lcd, task\n",
    "from tqdm import tqdm_notebook\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import getpass\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "usrname = getpass.getuser()\n",
    "\n",
    "print('Версия python3:', sys.version)\n",
    "print('Версия keras:', keras.__version__)\n",
    "print('Keras backend:', keras.backend.backend())\n",
    "print('Версия matplotlib:', matplotlib.__version__)\n",
    "print('Версия urlib.request', urllib.request.__version__)\n",
    "print('Версия numpy', np.__version__)\n",
    "print('Версия OpenCV:', cv2.__version__)\n",
    "print('Абсолютный путь к папке python3:', sys.executable)\n",
    "print('Имя пользователя', usrname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь скачаем данные. Это размеченные картинки кошек и собак с соревнования Kaggle. Получить доступ к ним с одноименного сайта проблематично. К счастью, на сайте Майкрософт эти данные тоже есть, поэтому скачивать будем оттуда. Обучение нейросети на практике занимает от одного дня до недели. К счастью, есть уже готовые веса, которые можно скачать из Яндекс.Диска. Поэтому напишем функции, которые позволят скачать файл с весами модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Скачать файл\n",
    "def download(url, target='./', filename=None, locally=True):\n",
    "    if filename:\n",
    "        command = 'wget -O \"%s\" \"%s\"' % (os.path.join(target, filename), url)\n",
    "    else:\n",
    "        command = 'wget \"%s\"' % url\n",
    "\n",
    "    if locally:\n",
    "        with lcd(target):\n",
    "            local(command)\n",
    "    else:\n",
    "        with cd(target):\n",
    "            run(command)\n",
    "\n",
    "# Скачать файл с Яндекс.Диска\n",
    "def disk_download(url, target='./', locally=True):\n",
    "    api = http.client.HTTPSConnection('cloud-api.yandex.net')\n",
    "    url ='/v1/disk/public/resources/download?public_key=%s' % urllib.parse.quote(url)\n",
    "    api.request('GET', url)\n",
    "    resp = api.getresponse()\n",
    "    file_info = json.loads(resp.read().decode(\"utf-8\"))\n",
    "    api.close()\n",
    "\n",
    "    if resp.status == 200:\n",
    "        filename = urllib.parse.parse_qs(urllib.parse.urlparse(file_info['href']).query)['filename'][0]\n",
    "        download(file_info['href'], target, filename, locally)\n",
    "    else:\n",
    "        print(resp.status, resp.reason)\n",
    "        print(file_info['error'], '\\n', file_info['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data_no_split = os.getcwd() + '/data_no_split/'\n",
    "path_to_zip_file = path_to_data_no_split + 'cat_dog_images.zip'\n",
    "weights_path = os.getcwd() + '/vgg16_weights.h5'\n",
    "bottleneck_model_weights_path = os.getcwd() + '/bottleneck_weights.h5'\n",
    "favorite_weights_path = os.getcwd() + '/favorite_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Создаем директорию, если таковая отсутствует\n",
    "if not os.path.exists(path_to_data_no_split):\n",
    "    os.makedirs(path_to_data_no_split)\n",
    "\n",
    "# Скачивание данных\n",
    "url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip'\n",
    "if not os.path.exists(path_to_zip_file):\n",
    "    urllib.request.urlretrieve(url, path_to_zip_file)\n",
    "\n",
    "# Распаковка архива\n",
    "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "if not os.path.exists(path_to_data_no_split+'PetImages/'):\n",
    "    zip_ref.extractall(path_to_data_no_split)\n",
    "zip_ref.close()\n",
    "\n",
    "# Cкачивание предообученной модели VGG16\n",
    "url = 'https://yadi.sk/d/86p7x3py3RHExW'\n",
    "if not os.path.exists(weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')\n",
    "\n",
    "# Cкачивание предообученной модели классификатора\n",
    "url = 'https://yadi.sk/d/v0JC9lw-3RSbfi'\n",
    "if not os.path.exists(bottleneck_model_weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')\n",
    "\n",
    "# Cкачивание предообученной модели\n",
    "url = 'https://yadi.sk/d/UYa5-0s43RSbDY'\n",
    "if not os.path.exists(favorite_weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо проверить картинки на качество: некоторые файлы могу быть \"битыми\". Для этого определим функцию `check_class_num`. В ней мы проверяем, сколько изображений можно использовать для обучения, сквозной проверки и теста. Заодно и получить список имен файлов, которые можно использовать. Он необходим для поэлементного чтения картинок для обучения, сквозной проверки и теста. Это выгодно, когда мало оперативной памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "n_folds = 2\n",
    "batch_size = 32\n",
    "val_split = .33  # Если не используем kfold\n",
    "classes = [\"dog\", \"cat\"]\n",
    "folders = [\"Dog\", \"Cat\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Разрешение изображения\n",
    "img_width, img_height = 224, 224\n",
    "num_channels = 3\n",
    "\n",
    "# Посчитать число небитых картинок\n",
    "def check_class_num():\n",
    "    cat_dog_num = {folders[0] : 0, folders[1] : 0}\n",
    "    cat_dog_list = {folders[0] : [], folders[1] : []}\n",
    "    \n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        path = os.path.join(path_to_data_no_split+'PetImages/', fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "        i = 0\n",
    "        \n",
    "        for fl in tqdm_notebook(files):\n",
    "            flbase = os.path.basename(fl)\n",
    "            try:\n",
    "                mpimg.imread(fl)\n",
    "            except:\n",
    "                continue\n",
    "            cat_dog_num[fld] += 1\n",
    "            cat_dog_list[fld] += [fl]\n",
    "            \n",
    "    return cat_dog_num, cat_dog_list\n",
    "\n",
    "# Загрузить изображения (Необхожимо следить за памятью)\n",
    "def load_images(cat_dog_list, img_count=100):\n",
    "    X = []\n",
    "    X_id = []\n",
    "    Y = []\n",
    "\n",
    "    print('Загрузка изображений для обучения...')\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        for fl in tqdm_notebook(cat_dog_list[fld][:min(img_count, len(cat_dog_list[fld]))]):\n",
    "            img = image.load_img(fl, target_size=(img_width, img_height))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            X.append(x[0])\n",
    "            X_id.append(fl)\n",
    "            Y.append(index)\n",
    "\n",
    "    X = np.array(X)\n",
    "    #X = X.transpose((0, 3, 1, 2)) # Зависит от backend'a - ставить для Threano\n",
    "    Y = np_utils.to_categorical(Y, num_classes)\n",
    "    print('Загрузка изображений завершена!')\n",
    "    return X, Y, X_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посчитаем число небитых изображений. После расчета видно, что картинок очень много. Это очень хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_dog_num, cat_dog_list = check_class_num()\n",
    "with open('cat_dog_list.json', 'w') as outfile:\n",
    "    json.dump(cat_dog_list, outfile)\n",
    "cat_dog_num['Dog'], cat_dog_num['Cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы \"очистили\" картинки от битых, надо загрузить их. Если памяти много, то можно загрузить все картинки. Однако сейчас у нас доступно не очень много памяти (MyBinder обеспечивает 8 Гб оперативной памяти, что очень мало). Поэтому загрузим часть картинок. Их количество обозначим `img_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_dog_list = json.load(open('cat_dog_list.json'))\n",
    "img_count = 200\n",
    "X, Y, X_id = load_images(cat_dog_list, img_count=img_count)\n",
    "np.shape(X), np.shape(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас определим модель нейронной сети VGG-16 с модификациями для бинарной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG16 архитертура с модификацией для бинарной классификации.\n",
    "def build_model():\n",
    "    \n",
    "    # VGG16\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # Загрузить веса для VGG16\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # Не берем последний полносвязный слой\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        weights_T = [np.array(x).T for x in weights]\n",
    "        weights = weights_T  \n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "    # Строим классификатор и вставляем его в конец сверточной сети\n",
    "    bottleneck_model = Sequential()\n",
    "    bottleneck_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    bottleneck_model.add(Dense(256, activation='relu'))\n",
    "    bottleneck_model.add(Dropout(0.5))\n",
    "    bottleneck_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Загружаем веса для классификатора\n",
    "    bottleneck_model.load_weights(bottleneck_model_weights_path)\n",
    "\n",
    "    # Добавляем классификатор в VGG16 архитектуру\n",
    "    model.add(bottleneck_model)\n",
    "\n",
    "    # Веса до последнего сверточного блока оставляем без изменения во время дообучения\n",
    "    for layer in model.layers[:25]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Компилируем\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим модель и загрузим для нее веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "model = build_model()\n",
    "model.load_weights(favorite_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_dog_count = img_count * 2\n",
    "X_train, X_valid, Y_train, Y_valid =\\\n",
    "train_test_split(X[:min(cat_dog_count, len(X))], Y[:min(cat_dog_count, len(Y))], test_size=val_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем используем модель и отобразим результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(\"no images to show\")\n",
    "        return \n",
    "    else:\n",
    "        random_indices = random.sample(range(len(images)), min(len(images), 9))\n",
    "            \n",
    "    if cls_pred is None:\n",
    "        images, cls_true = zip(*[(images[i], cls_true[i]) for i in random_indices])\n",
    "    else:\n",
    "        images, cls_true, cls_pred = zip(*[(images[i], cls_true[i], cls_pred[i]) for i in random_indices])\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        image = images[i]\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors_rights(cls_pred, correct):\n",
    "    # This function is called from print_validation_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the validation set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the validation set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the validation set that have been\n",
    "    # incorrectly classified.\n",
    "    images = [image.load_img(x_id, target_size=(img_width, img_height)) for x_id in list(compress(X_id, list(incorrect)))]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    labels = np.array([classes[np.argmax(x)] for x in Y_valid])\n",
    "    cls_true = labels[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_example_errors_rights(cls_pred, correct):\n",
    "    # This function is called from print_validation_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the validation set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the validation set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the validation set that have been\n",
    "    # incorrectly classified.\n",
    "    images_incorrect = X_valid[incorrect,:,:]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred_incorrect = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    labels = Y_valid[0]\n",
    "    cls_true_incorrect = labels[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    print('Incorrect')\n",
    "    plot_images(images=images_incorrect[0:9],\n",
    "                cls_true=cls_true_incorrect[0:9],\n",
    "                cls_pred=cls_pred_incorrect[0:9])\n",
    "    \n",
    "    # Get the images from the validation set that have been\n",
    "    # incorrectly classified.\n",
    "    images_correct = X_valid[correct,:,:]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred_correct = cls_pred[correct]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true_correct = labels[correct]\n",
    "    \n",
    "    print('Correct')\n",
    "    plot_images(images=images_correct[0:9],\n",
    "                cls_true=cls_true_correct[0:9],\n",
    "                cls_pred=cls_pred_correct[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_validation_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the validation set.\n",
    "\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = [classes[np.argmax(x)] for x in Y_valid]\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred,\n",
    "                          labels=classes)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_validation_accuracy(show_example_errors_rights=False, show_confusion_matrix=False):\n",
    "    \n",
    "    cls_pred = np.array([classes[np.argmax(x)] for x in model.predict(X_valid)])\n",
    "    \n",
    "    # Convenience variable for the true class-numbers of the validation set.\n",
    "    cls_true = np.array([classes[np.argmax(x)] for x in Y_valid])\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / len(Y_valid)\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on validation set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, len(Y_valid)))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors_rights:\n",
    "        print(\"Example errors and rights:\")\n",
    "        plot_example_errors_rights(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print_validation_accuracy(show_example_errors_rights=True, show_confusion_matrix=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "064dca66b06f48fb9c502c1c8f7280f8": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "308791e0462145adb74410ea5f5acc43": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "73ef8b2409ed48cf914c4d8fb0338ca4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "8800411da8e64ed8953b5b48a7f99b55": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "cc5595df510140b1af50683d81387b8b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "f6ed7cd8149148beae25d7d17d269869": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "fb2eeb32c58f4ad68284804dea4b7d24": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
