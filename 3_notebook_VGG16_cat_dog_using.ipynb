{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование предобученной модели нейросети на основе M-VGG16\n",
    "\n",
    "Решение задачи классификации образов (кошек и собак) с помощью keras. \n",
    "\n",
    "Для начала подключим необходимые модули и выведем их версии, в том числе версию python3. \n",
    "Также выведем абсолютный путь к папке с python3 (для разработчиков).\n",
    "\n",
    "Ссылки на сторонние библиотеки:\n",
    "\n",
    "[matplotlib](https://matplotlib.org/)\n",
    "\n",
    "[keras](https://keras.io/)\n",
    "\n",
    "[urllib python3](https://urllib3.readthedocs.io/en/latest/)\n",
    "\n",
    "[numpy](http://www.numpy.org/)\n",
    "\n",
    "[OpenCV python3](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html)\n",
    "\n",
    "Нажмите `Shift+Enter`, чтобы выполнить код в ячейке. Или нажмите `Kernel --> Restart and Run All` для запуска всех ячеек по очереди."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import http.client\n",
    "\n",
    "import json\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import random\n",
    "\n",
    "from fabric.api import execute, local, run, lcd, task\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "import sys\n",
    "\n",
    "import getpass\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import glob\n",
    "\n",
    "usrname = getpass.getuser()\n",
    "\n",
    "print('Версия python3:', sys.version)\n",
    "print('Версия keras:', keras.__version__)\n",
    "print('Keras backend:', keras.backend.backend())\n",
    "print('Версия matplotlib:', matplotlib.__version__)\n",
    "print('Версия urlib.request', urllib.request.__version__)\n",
    "print('Версия numpy', np.__version__)\n",
    "print('Версия OpenCV:', cv2.__version__)\n",
    "print('Абсолютный путь к папке python3:', sys.executable)\n",
    "print('Имя пользователя', usrname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь скачаем данные. Это размеченные картинки кошек и собак с соревнования Kaggle. Получить доступ к ним с одноименного сайта проблематично. К счастью, на сайте Майкрософт эти данные тоже есть, поэтому скачивать будем оттуда. Обучение нейросети на практике занимает от одного дня до недели. К счастью, есть уже готовые веса, которые можно скачать из Яндекс.Диска. Поэтому напишем функции, которые позволят скачать файл с весами модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Скачать файл\n",
    "def download(url, target='./', filename=None, locally=True):\n",
    "    if filename:\n",
    "        command = 'wget -O \"%s\" \"%s\"' % (os.path.join(target, filename), url)\n",
    "    else:\n",
    "        command = 'wget \"%s\"' % url\n",
    "\n",
    "    if locally:\n",
    "        with lcd(target):\n",
    "            local(command)\n",
    "    else:\n",
    "        with cd(target):\n",
    "            run(command)\n",
    "\n",
    "# Скачать файл с Яндекс.Диска\n",
    "def disk_download(url, target='./', locally=True):\n",
    "    api = http.client.HTTPSConnection('cloud-api.yandex.net')\n",
    "    url ='/v1/disk/public/resources/download?public_key=%s' % urllib.parse.quote(url)\n",
    "    api.request('GET', url)\n",
    "    resp = api.getresponse()\n",
    "    file_info = json.loads(resp.read().decode(\"utf-8\"))\n",
    "    api.close()\n",
    "\n",
    "    if resp.status == 200:\n",
    "        filename = urllib.parse.parse_qs(urllib.parse.urlparse(file_info['href']).query)['filename'][0]\n",
    "        download(file_info['href'], target, filename, locally)\n",
    "    else:\n",
    "        print(resp.status, resp.reason)\n",
    "        print(file_info['error'], '\\n', file_info['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data_no_split = os.getcwd() + '/data_no_split/'\n",
    "path_to_zip_file = path_to_data_no_split + 'cat_dog_images.zip'\n",
    "weights_path = os.getcwd() + '/vgg16_weights.h5'\n",
    "bottleneck_model_weights_path = os.getcwd() + '/bottleneck_weights.h5'\n",
    "favorite_weights_path = os.getcwd() + '/favorite_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Создаем директорию, если таковая отсутствует\n",
    "if not os.path.exists(path_to_data_no_split):\n",
    "    os.makedirs(path_to_data_no_split)\n",
    "\n",
    "# Скачивание данных\n",
    "url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip'\n",
    "if not os.path.exists(path_to_zip_file):\n",
    "    urllib.request.urlretrieve(url, path_to_zip_file)\n",
    "\n",
    "# Распаковка архива\n",
    "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "if not os.path.exists(path_to_data_no_split+'PetImages/'):\n",
    "    zip_ref.extractall(path_to_data_no_split)\n",
    "zip_ref.close()\n",
    "\n",
    "# Cкачивание предообученной модели VGG16\n",
    "url = 'https://yadi.sk/d/86p7x3py3RHExW'\n",
    "if not os.path.exists(weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')\n",
    "\n",
    "# Cкачивание предообученной модели классификатора\n",
    "url = 'https://yadi.sk/d/v0JC9lw-3RSbfi'\n",
    "if not os.path.exists(bottleneck_model_weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')\n",
    "\n",
    "# Cкачивание предообученной модели\n",
    "url = 'https://yadi.sk/d/UYa5-0s43RSbDY'\n",
    "if not os.path.exists(favorite_weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо проверить картинки на качество: некоторые файлы могу быть \"битыми\". Для этого определим функцию `check_class_num`. В ней мы проверяем, сколько изображений можно использовать для обучения, сквозной проверки и теста. Заодно и получить список имен файлов, которые можно использовать. Он необходим для поэлементного чтения картинок для обучения, сквозной проверки и теста. Это выгодно, когда мало оперативной памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "val_split = .33 \n",
    "classes = [\"dog\", \"cat\"]\n",
    "folders = [\"Dog\", \"Cat\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Разрешение изображения\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Посчитать число небитых картинок\n",
    "def check_class_num():\n",
    "    cat_dog_num = {folders[0] : 0, folders[1] : 0}\n",
    "    cat_dog_list = {folders[0] : [], folders[1] : []}\n",
    "    \n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        path = os.path.join(path_to_data_no_split+'PetImages/', fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "        i = 0\n",
    "        \n",
    "        for fl in tqdm_notebook(files):\n",
    "            flbase = os.path.basename(fl)\n",
    "            try:\n",
    "                img = cv2.imread(fl)\n",
    "                resized = cv2.resize(img, (img_width, img_height), cv2.INTER_LINEAR)\n",
    "            except:\n",
    "                continue\n",
    "            cat_dog_num[fld] += 1\n",
    "            cat_dog_list[fld] += [fl]\n",
    "            \n",
    "    return cat_dog_num, cat_dog_list\n",
    "\n",
    "# Загрузить изображения (Необходимо следить за памятью)\n",
    "def load_images(cat_dog_list, img_count=100):\n",
    "    X = []\n",
    "    X_id = []\n",
    "    Y = []\n",
    "    images = []\n",
    "\n",
    "    print('Загрузка изображений для обучения...')\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        for fl in tqdm_notebook(cat_dog_list[fld][:min(img_count, len(cat_dog_list[fld]))]):\n",
    "            img = image.load_img(fl, target_size=(img_width, img_height))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            X.append(x[0])\n",
    "            images.append(img)\n",
    "            X_id.append(fl)\n",
    "            Y.append(index)\n",
    "\n",
    "    X = np.array(X)\n",
    "    #X = X.transpose((0, 3, 1, 2)) # Зависит от backend'a - ставить для Threano\n",
    "    Y = np_utils.to_categorical(Y, num_classes)\n",
    "    print('Загрузка изображений завершена!')\n",
    "    return X, Y, X_id, images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посчитаем число небитых изображений. После расчета видно, что картинок очень много. Это очень хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_dog_num, cat_dog_list = check_class_num()\n",
    "with open('cat_dog_list.json', 'w') as outfile:\n",
    "    json.dump(cat_dog_list, outfile)\n",
    "cat_dog_num['Dog'], cat_dog_num['Cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы \"очистили\" картинки от битых, надо загрузить их. Если памяти много, то можно загрузить все картинки. Однако сейчас у нас доступно не очень много памяти (MyBinder обеспечивает 8 Гб оперативной памяти, что очень мало). Поэтому загрузим часть картинок. Их количество обозначим `img_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_dog_list = json.load(open('cat_dog_list.json'))\n",
    "img_count = 5\n",
    "X, Y, X_id, images = load_images(cat_dog_list, img_count=img_count)\n",
    "np.shape(X), np.shape(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас определим модель нейронной сети VGG-16 с модификациями для бинарной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG16 архитертура с модификацией для бинарной классификации.\n",
    "def build_model():\n",
    "    \n",
    "    # VGG16\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # Загрузить веса для VGG16\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # Не берем последний полносвязный слой\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        weights_T = [np.array(x).T for x in weights]\n",
    "        weights = weights_T  \n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "    # Строим классификатор и вставляем его в конец сверточной сети\n",
    "    bottleneck_model = Sequential()\n",
    "    bottleneck_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    bottleneck_model.add(Dense(256, activation='relu'))\n",
    "    bottleneck_model.add(Dropout(0.5))\n",
    "    bottleneck_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Загружаем веса для классификатора\n",
    "    bottleneck_model.load_weights(bottleneck_model_weights_path)\n",
    "\n",
    "    # Добавляем классификатор в VGG16 архитектуру\n",
    "    model.add(bottleneck_model)\n",
    "\n",
    "    # Веса до последнего сверточного блока оставляем без изменения во время дообучения\n",
    "    for layer in model.layers[:25]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Компилируем\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим модель и загрузим для нее веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "model = build_model()\n",
    "model.load_weights(favorite_weights_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_valid = X\n",
    "Y_valid = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем используем модель и отобразим результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(\"no images to show\")\n",
    "        return \n",
    "    else:\n",
    "        random_indices = random.sample(range(len(images)), min(len(images), 9))\n",
    "            \n",
    "    if cls_pred is None:\n",
    "        images, cls_true = zip(*[(images[i], cls_true[i]) for i in random_indices])\n",
    "    else:\n",
    "        images, cls_true, cls_pred = zip(*[(images[i], cls_true[i], cls_pred[i]) for i in random_indices])\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        image = images[i]\n",
    "        ax.imshow(image)\n",
    "\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example(cls_pred):\n",
    "\n",
    "    labels = np.array([classes[np.argmax(x)] for x in Y_valid])\n",
    "    cls_true = labels\n",
    "    \n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    cls_true = [classes[np.argmax(x)] for x in Y_valid]\n",
    "    \n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred,\n",
    "                          labels=classes)\n",
    "\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_validation_accuracy(show_example=False, show_confusion_matrix=False):\n",
    "    \n",
    "    cls_pred = np.array([classes[np.argmax(x)] for x in model.predict(X_valid)])\n",
    "    \n",
    "    cls_true = np.array([classes[np.argmax(x)] for x in Y_valid])\n",
    "\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    acc = float(correct_sum) / len(Y_valid)\n",
    "\n",
    "    msg = \"Точность на тесте: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, len(Y_valid)))\n",
    "\n",
    "    if show_example:\n",
    "        print(\"Примеры:\")\n",
    "        plot_example(cls_pred=cls_pred)\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Матрица неточностей:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print_validation_accuracy(show_example=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на других изображениях, которые не были в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_img_show(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')  # Очистка от разметки осей\n",
    "    print('Предсказание: На картинке Dasha.jpg изображена', classes[np.argmax(preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_img_show('Dasha.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_img_show('Tosha.jpg')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0729a2b6dcb04bfe8e5bf00d4c6e745d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d0376134729347c79fed67e22593be39": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "da986371ca474d368150f207dfac228f": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "e49d9f06b2bd485883522d9d9c0ef984": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
