{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat & dog image classification\n",
    "\n",
    "Выполнил: студент группы А-14м-16 Мигаль Иван.\n",
    "\n",
    "Описание:\n",
    "\n",
    "Решение задачи классификации образов (кошек и собак) с помощью keras. \n",
    "\n",
    "Для начала подключим необходимые модули и выведем их версии, в том числе версию python3. \n",
    "Также выведем абсолютный путь к папке с python3 (для разработчиков)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия python3: 3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Версия keras: 2.0.9\n",
      "Версия matplotlib: 1.5.3\n",
      "Версия urlib.request 3.5\n",
      "Версия numpy 1.11.1\n",
      "Версия OpenCV: 3.2.0\n",
      "Абсолютный путь к папке python3: /home/ivmig/anaconda3/bin/python\n",
      "Имя пользователя ivmig\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import matplotlib\n",
    "import urllib.request\n",
    "import http.client\n",
    "import json\n",
    "from fabric.api import execute, local, run, lcd, task\n",
    "from tqdm import tqdm_notebook\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import getpass\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "usrname = getpass.getuser()\n",
    "\n",
    "print('Версия python3:', sys.version)\n",
    "print('Версия keras:', keras.__version__)\n",
    "print('Версия matplotlib:', matplotlib.__version__)\n",
    "print('Версия urlib.request', urllib.request.__version__)\n",
    "print('Версия numpy', np.__version__)\n",
    "print('Версия OpenCV:', cv2.__version__)\n",
    "print('Абсолютный путь к папке python3:', sys.executable)\n",
    "print('Имя пользователя', usrname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь скачаем данные. Это размеченные картинки кошек и собак с соревнования Kaggle. Получить доступ к ним с одноименного сайта проблематично. К счастью, на сайте Майкрософт эти данные тоже есть, поэтому скачивать будем оттуда. Обучение нейросети на практике занимает от одного дня до недели. К счастью, есть уже готовые веса, которые можно скачать из Яндекс.Диска. Поэтому напишем функции, которые позволят скачать файл с весами модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Скачать файл\n",
    "def download(url, target='./', filename=None, locally=True):\n",
    "    if filename:\n",
    "        command = 'wget -O \"%s\" \"%s\"' % (os.path.join(target, filename), url)\n",
    "    else:\n",
    "        command = 'wget \"%s\"' % url\n",
    "\n",
    "    if locally:\n",
    "        with lcd(target):\n",
    "            local(command)\n",
    "    else:\n",
    "        with cd(target):\n",
    "            run(command)\n",
    "\n",
    "# Скачать файл с Яндекс.Диска\n",
    "def disk_download(url, target='./', locally=True):\n",
    "    api = http.client.HTTPSConnection('cloud-api.yandex.net')\n",
    "    url ='/v1/disk/public/resources/download?public_key=%s' % urllib.parse.quote(url)\n",
    "    api.request('GET', url)\n",
    "    resp = api.getresponse()\n",
    "    file_info = json.loads(resp.read().decode(\"utf-8\"))\n",
    "    api.close()\n",
    "\n",
    "    if resp.status == 200:\n",
    "        filename = urllib.parse.parse_qs(urllib.parse.urlparse(file_info['href']).query)['filename'][0]\n",
    "        print(filename)\n",
    "        download(file_info['href'], target, filename, locally)\n",
    "    else:\n",
    "        print(resp.status, resp.reason)\n",
    "        print(file_info['error'], '\\n', file_info['description'])\n",
    "\n",
    "        \n",
    "path_to_data_no_split = os.getcwd() + '/data_no_split/'\n",
    "path_to_zip_file = path_to_data_no_split + 'cat_dog_images.zip'        \n",
    "weights_path = os.getcwd() + '/vgg16_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 332 ms, sys: 180 ms, total: 512 ms\n",
      "Wall time: 709 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Создаем директорию, если таковая отсутствует\n",
    "if not os.path.exists(path_to_data_no_split):\n",
    "    os.makedirs(path_to_data_no_split)\n",
    "\n",
    "# Скачивание данных\n",
    "url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip'\n",
    "if not os.path.exists(path_to_zip_file):\n",
    "    urllib.request.urlretrieve(url, path_to_zip_file)\n",
    "\n",
    "# Распаковка архива\n",
    "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "if not os.path.exists(path_to_data_no_split+'PetImages/'):\n",
    "    zip_ref.extractall(path_to_data_no_split)\n",
    "zip_ref.close()\n",
    "\n",
    "# Cкачивание предообученной модели\n",
    "url = 'https://yadi.sk/d/86p7x3py3RHExW'\n",
    "if not os.path.exists(weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо проверить картинки на качество: некоторые файлы могу быть \"битыми\". Для этого определим функцию `check_class_num`. В ней мы проверяем, сколько изображений можно использовать для обучения, сквозной проверки и теста. Заодно и получить список имен файлов, которые можно использовать. Он необходим для поэлементного чтения картинок для обучения, сквозной проверки и теста. Это выгодно, когда мало оперативной памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### other hyperparameters\n",
    "n_folds = 2\n",
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "bottleneck_epoch = 3  # used when training bottleneck model\n",
    "val_split = .15  # if not using kfold cv\n",
    "classes = [\"dog\", \"cat\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "### image dimensions\n",
    "img_width, img_height = 250, 250\n",
    "num_channels = 3\n",
    "\n",
    "# Посчитать число небитых картинок\n",
    "def check_class_num(img_begin=0, img_count=100):\n",
    "    folders = [\"Dog\", \"Cat\"]\n",
    "    cat_dog_num = {folders[0] : 0, folders[1] : 0}\n",
    "    cat_dog_list = {folders[0] : [], folders[1] : []}\n",
    "    \n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        path = os.path.join(path_to_data_no_split+'PetImages/', fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "        i = 0\n",
    "        \n",
    "        for fl in tqdm_notebook(files[img_begin:img_begin+img_count]):\n",
    "            flbase = os.path.basename(fl)\n",
    "            try:\n",
    "                img = cv2.imread(fl)\n",
    "                resized = cv2.resize(img, (img_width, img_height), cv2.INTER_LINEAR)\n",
    "            except:\n",
    "                continue\n",
    "            cat_dog_num[fld] += 1\n",
    "            cat_dog_list[fld] += [fl]\n",
    "            \n",
    "    return cat_dog_num, cat_dog_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9976, 0.99808)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dog_num, cat_dog_list = check_class_num(img_begin=0, img_count=12500)\n",
    "cat_dog_num['Dog'] / 12500, cat_dog_num['Cat'] / 12500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные числа говорят о том, что количества объектов разных классов примерно одинаковы. Это позволяет использовать метрику Точность (Accuracy) для оценки качества. Сейчас создадим модель нейронной сети VGG-16 с весами, натреннированными ранее. Затем дообучим её и сделаем тесты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = [cat_dog_list['Dog']] + [cat_dog_list['Cat']]\n",
    "train_target = [0] * len(cat_dog_list['Dog']) + [1] * len(cat_dog_list['Cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # load the weights of the VGG16 networks\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    bottleneck_model = Sequential()\n",
    "    bottleneck_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    bottleneck_model.add(Dense(256, activation='relu'))\n",
    "    bottleneck_model.add(Dropout(0.5))\n",
    "    bottleneck_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # load weights from bottleneck model\n",
    "    bottleneck_model.load_weights(os.getcwd() + '/bottleneck_weights.h5')\n",
    "\n",
    "    # add the model on top of the convolutional base\n",
    "    model.add(bottleneck_model)\n",
    "\n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:25]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # load the weights of the VGG16 networks\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    print('Model loaded.')\n",
    "    \n",
    "    # create validation split\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_target, test_size=val_split)\n",
    "\n",
    "    # create generator for train data\n",
    "    generator = datagen.flow(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False)\n",
    "    \n",
    "    # save train features to .npy file\n",
    "    bottleneck_features_train = model.predict_generator(generator, X_train.shape[0])\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "    # create generator for validation data\n",
    "    generator = datagen.flow(\n",
    "            X_valid,\n",
    "            Y_valid,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False)\n",
    "    \n",
    "    # save validation features to .npy file\n",
    "    bottleneck_features_validation = model.predict_generator(generator, X_valid.shape[0])\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "    return Y_train, Y_valid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### other hyperparameters\n",
    "n_folds = 2\n",
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "bottleneck_epoch = 3  # used when training bottleneck model\n",
    "val_split = .15  # if not using kfold cv\n",
    "\n",
    "VGG16 = keras.applications.vgg16.VGG16(include_top=False, classes=2)\n",
    "\n",
    "# Классы\n",
    "classes = [\"dog\", \"cat\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Загрузить изображение\n",
    "def load_images(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (img_width, img_height), cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "img_path = cat_dog_list['Dog'][0]\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=1)[0][0][1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывести рисунки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(\"no images to show\")\n",
    "        return \n",
    "    else:\n",
    "        random_indices = random.sample(range(len(images)), min(len(images), 9))\n",
    "            \n",
    "    images, cls_true  = zip(*[(images[i], cls_true[i]) for i in random_indices])\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        image = images[i].transpose((1, 2, 0))\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "08207be94daa4c3998afb45a7b8d6439": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "bef923cd1d8c4999979fce44ba5dded0": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
