{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat & dog image classification with Keras\n",
    "\n",
    "Выполнил: студент группы А-14м-16 Мигаль Иван.\n",
    "\n",
    "Описание:\n",
    "\n",
    "Решение задачи классификации образов (кошек и собак) с помощью keras. \n",
    "\n",
    "Для начала подключим необходимые модули и выведем их версии, в том числе версию python3. \n",
    "Также выведем абсолютный путь к папке с python3 (для разработчиков)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import matplotlib\n",
    "import urllib.request\n",
    "import http.client\n",
    "import json\n",
    "from itertools import compress\n",
    "import random\n",
    "from fabric.api import execute, local, run, lcd, task\n",
    "from tqdm import tqdm_notebook\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import getpass\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "usrname = getpass.getuser()\n",
    "\n",
    "print('Версия python3:', sys.version)\n",
    "print('Версия keras:', keras.__version__)\n",
    "print('Keras backend:', keras.backend.backend())\n",
    "print('Версия matplotlib:', matplotlib.__version__)\n",
    "print('Версия urlib.request', urllib.request.__version__)\n",
    "print('Версия numpy', np.__version__)\n",
    "print('Версия OpenCV:', cv2.__version__)\n",
    "print('Абсолютный путь к папке python3:', sys.executable)\n",
    "print('Имя пользователя', usrname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь скачаем данные. Это размеченные картинки кошек и собак с соревнования Kaggle. Получить доступ к ним с одноименного сайта проблематично. К счастью, на сайте Майкрософт эти данные тоже есть, поэтому скачивать будем оттуда. Обучение нейросети на практике занимает от одного дня до недели. К счастью, есть уже готовые веса, которые можно скачать из Яндекс.Диска. Поэтому напишем функции, которые позволят скачать файл с весами модели."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Скачать файл\n",
    "def download(url, target='./', filename=None, locally=True):\n",
    "    if filename:\n",
    "        command = 'wget -O \"%s\" \"%s\"' % (os.path.join(target, filename), url)\n",
    "    else:\n",
    "        command = 'wget \"%s\"' % url\n",
    "\n",
    "    if locally:\n",
    "        with lcd(target):\n",
    "            local(command)\n",
    "    else:\n",
    "        with cd(target):\n",
    "            run(command)\n",
    "\n",
    "# Скачать файл с Яндекс.Диска\n",
    "def disk_download(url, target='./', locally=True):\n",
    "    api = http.client.HTTPSConnection('cloud-api.yandex.net')\n",
    "    url ='/v1/disk/public/resources/download?public_key=%s' % urllib.parse.quote(url)\n",
    "    api.request('GET', url)\n",
    "    resp = api.getresponse()\n",
    "    file_info = json.loads(resp.read().decode(\"utf-8\"))\n",
    "    api.close()\n",
    "\n",
    "    if resp.status == 200:\n",
    "        filename = urllib.parse.parse_qs(urllib.parse.urlparse(file_info['href']).query)['filename'][0]\n",
    "        print(filename)\n",
    "        download(file_info['href'], target, filename, locally)\n",
    "    else:\n",
    "        print(resp.status, resp.reason)\n",
    "        print(file_info['error'], '\\n', file_info['description'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path_to_data_no_split = os.getcwd() + '/data_no_split/'\n",
    "path_to_zip_file = path_to_data_no_split + 'cat_dog_images.zip'\n",
    "bottleneck_model_weights_path = os.getcwd() + '/bottleneck_weights.h5'\n",
    "weights_path = os.getcwd() + '/vgg16_weights.h5'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "\n",
    "# Создаем директорию, если таковая отсутствует\n",
    "if not os.path.exists(path_to_data_no_split):\n",
    "    os.makedirs(path_to_data_no_split)\n",
    "\n",
    "# Скачивание данных\n",
    "url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip'\n",
    "if not os.path.exists(path_to_zip_file):\n",
    "    urllib.request.urlretrieve(url, path_to_zip_file)\n",
    "\n",
    "# Распаковка архива\n",
    "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "if not os.path.exists(path_to_data_no_split+'PetImages/'):\n",
    "    zip_ref.extractall(path_to_data_no_split)\n",
    "zip_ref.close()\n",
    "\n",
    "# Cкачивание предообученной модели\n",
    "url = 'https://yadi.sk/d/86p7x3py3RHExW'\n",
    "if not os.path.exists(weights_path):\n",
    "    disk_download(url, target=os.getcwd() + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо проверить картинки на качество: некоторые файлы могу быть \"битыми\". Для этого определим функцию `check_class_num`. В ней мы проверяем, сколько изображений можно использовать для обучения, сквозной проверки и теста. Заодно и получить список имен файлов, которые можно использовать. Он необходим для поэлементного чтения картинок для обучения, сквозной проверки и теста. Это выгодно, когда мало оперативной памяти."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Гиперпараметры\n",
    "n_folds = 2\n",
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "bottleneck_epoch = 50  # Используем для обучении надстройки для VGG16\n",
    "val_split = .33  # Если не используем kfold\n",
    "classes = [\"dog\", \"cat\"]\n",
    "folders = [\"Dog\", \"Cat\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Разрешение изображения\n",
    "img_width, img_height = 224, 224\n",
    "num_channels = 3\n",
    "\n",
    "# Посчитать число небитых картинок\n",
    "def check_class_num():\n",
    "    cat_dog_num = {folders[0] : 0, folders[1] : 0}\n",
    "    cat_dog_list = {folders[0] : [], folders[1] : []}\n",
    "    \n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        path = os.path.join(path_to_data_no_split+'PetImages/', fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "        i = 0\n",
    "        \n",
    "        for fl in tqdm_notebook(files):\n",
    "            flbase = os.path.basename(fl)\n",
    "            try:\n",
    "                mpimg.imread(fl)\n",
    "            except:\n",
    "                continue\n",
    "            cat_dog_num[fld] += 1\n",
    "            cat_dog_list[fld] += [fl]\n",
    "            \n",
    "    return cat_dog_num, cat_dog_list\n",
    "\n",
    "# Загрузить изображения (Необхожимо следить за памятью)\n",
    "def load_images(cat_dog_list, img_count=100):\n",
    "    X = []\n",
    "    X_id = []\n",
    "    Y = []\n",
    "\n",
    "    print('Загрузка изображений для обучения...')\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        for fl in tqdm_notebook(cat_dog_list[fld][:min(img_count, len(cat_dog_list[fld]))]):\n",
    "            fl = fl.replace('/ivmig/git_repositories/', '/i.migal/')\n",
    "            img = image.load_img(fl, target_size=(img_width, img_height))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            X.append(x[0])\n",
    "            X_id.append(fl)\n",
    "            Y.append(index)\n",
    "\n",
    "    X = np.array(X)\n",
    "    #X = X.transpose((0, 3, 1, 2)) # Зависит от backend'a - ставить для Threano\n",
    "    Y = np_utils.to_categorical(Y, num_classes)\n",
    "    print('Загрузка изображений завершена!')\n",
    "    return X, Y, X_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посчитаем число небитых изображений. После расчета видно, что картинок очень много. Это очень хорошо"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cat_dog_num, cat_dog_list = check_class_num()\n",
    "with open('cat_dog_list.json', 'w') as outfile:\n",
    "    json.dump(cat_dog_list, outfile)\n",
    "cat_dog_num['Dog'], cat_dog_num['Cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы \"очистили\" картинки от битых, надо загрузить их. Если памяти много, то можно загрузить все картинки. Однако сейчас у нас доступно не очень много памяти (MyBinder обеспечивает 6 Гб оперативной памяти, что очень мало). Поэтому загрузим часть картинок. Их количество обозначим `img_count`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cat_dog_list = json.load(open('cat_dog_list.json'))\n",
    "img_count = 12500\n",
    "X, Y, X_id = load_images(cat_dog_list, img_count=img_count)\n",
    "np.shape(X), np.shape(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас определим модель нейронной сети VGG-16 с модификациями для бинарной классификации с весами, натреннированными ранее. Затем дообучим её и сделаем тесты."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG16 архитертура с модификацией для бинарной классификации.\n",
    "def build_model():\n",
    "    \n",
    "    # VGG16\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # Загрузить веса для VGG16\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # Не берем последний полносвязный слой\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        weights_T = [np.array(x).T for x in weights]\n",
    "        weights = weights_T  \n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "    # Строим классификатор и вставляем его в конец сверточной сети\n",
    "    bottleneck_model = Sequential()\n",
    "    bottleneck_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    bottleneck_model.add(Dense(256, activation='relu'))\n",
    "    bottleneck_model.add(Dropout(0.5))\n",
    "    bottleneck_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Загружаем веса для классификатора\n",
    "    bottleneck_model.load_weights(os.getcwd() + '/bottleneck_weights.h5')\n",
    "\n",
    "    # Добавляем классификатор в VGG16 архитектуру\n",
    "    model.add(bottleneck_model)\n",
    "\n",
    "    # Веса до последнего сверточного блока оставляем без изменения во время дообучения\n",
    "    for layer in model.layers[:25]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Компилируем\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Сохранить признаки классификатора\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # VGG16\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Загрузить веса для VGG16\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in tqdm_notebook(range(f.attrs['nb_layers'])):\n",
    "        if k >= len(model.layers):\n",
    "            # Не берем последний полносвязный слой\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        weights_T = [np.array(x).T for x in weights]\n",
    "        weights = weights_T  \n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    print('Model loaded.')\n",
    "    \n",
    "    # Разделение на обучения и проверку\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=val_split)\n",
    "    if not os.path.exists(os.getcwd() + '/bottleneck_features_train.npy') and\\\n",
    "       not os.path.exists(os.getcwd() + '/bottleneck_features_validation.npy'):\n",
    "\n",
    "        print('X_train', X_train.shape[0])\n",
    "        # Создать генератор для данных обучения\n",
    "        generator = datagen.flow(\n",
    "                X_train, Y_train,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                seed=42)\n",
    "\n",
    "        # Сохранить признаки обучения в .npy файл\n",
    "        bottleneck_features_train = model.predict_generator(generator, X_train.shape[0] // batch_size + 1, verbose=1)\n",
    "        print('Shape bottleneck_features_train', bottleneck_features_train.shape)\n",
    "        np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "        del bottleneck_features_train\n",
    "\n",
    "        print('X_valid', X_valid.shape[0])\n",
    "        # Создать генератор для данных проверки\n",
    "        generator = datagen.flow(\n",
    "                X_valid,\n",
    "                Y_valid,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                seed=42)\n",
    "\n",
    "        # Сохранить признаки проверки в .npy файл\n",
    "        bottleneck_features_validation = model.predict_generator(generator, X_valid.shape[0] // batch_size + 1, verbose=1)\n",
    "        print('Shape bottleneck_features_validation', bottleneck_features_validation.shape)\n",
    "        np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "        del bottleneck_features_validation\n",
    "    return Y_train, Y_valid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class EarlyStoppingByLossVal(Callback):\n",
    "    \"\"\"Custom class to set a val loss target for early stopping\"\"\"\n",
    "    def __init__(self, monitor='val_loss', value=0.45, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "### settings for keras early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1, mode='auto')\n",
    "# early_stopping = EarlyStoppingByLossVal(verbose=2, value=0.3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def train_bottleneck_model():\n",
    "    train_labels, validation_labels = save_bottleneck_features()\n",
    "\n",
    "    train_data = np.load(open('bottleneck_features_train.npy', 'rb'))\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "    print(len(train_labels), len(validation_labels), train_data.shape, validation_data.shape)\n",
    "    model.fit(train_data,\n",
    "              train_labels,\n",
    "              epochs=bottleneck_epoch,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=2)\n",
    "    \n",
    "    model.save_weights(bottleneck_model_weights_path)\n",
    "    print('Веса сохранены!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "\n",
    "train_bottleneck_model()  # leave this commented out once it's been done once -- takes a while to run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def run_train(cat_dog_count=100): \n",
    "    callbacks = [early_stopping]\n",
    "    \n",
    "    model = build_model()\n",
    "        \n",
    "    X_train, X_valid, Y_train, Y_valid =\\\n",
    "    train_test_split(X_[:min(cat_dog_count, len(X_))], Y_[:min(cat_dog_count, len(Y_))], test_size=val_split)\n",
    "    print('Training...')\n",
    "    print('Size of train split: ', len(X_train), len(Y_train))\n",
    "    print('Size of validation split: ', len(X_valid), len(Y_valid))\n",
    "              \n",
    "    model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, Y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "    predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "    score = log_loss(Y_valid, predictions_valid)\n",
    "    print('Loss: ', score)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%%time\n",
    "\n",
    "cat_dog_count = img_count * 2\n",
    "model = run_train(cat_dog_count=cat_dog_count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save_weights(\"favorite_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
